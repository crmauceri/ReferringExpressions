import torch

from SimpleClassifier_with_Tokens import LSTMClassifier
from SimpleClassifier_with_Images import LSTMPlusImageClassifier
from StackedAttentionNetwork import SAN

from DataLoader import DataLoader, Instance, load_data
import torchvision.datasets as dset

import csv, argparse, math, re

from sklearn.metrics import confusion_matrix, classification_report
from sklearn.preprocessing import MultiLabelBinarizer


def save_prediction_csv(data, predictions, labels, savefile):
    with open(savefile + '_predictions.csv', 'w') as csvfile:
        fieldnames = ['sentence', 'ground_truth', 'top_prediction', 'match', 'score']
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        writer.writeheader()
        for i, d in enumerate(data):
            sentence = " ".join(d.query)
            writer.writerow({'sentence': sentence, 'ground_truth': d.answer,
                             'top_prediction': labels[predictions[i][0]],
                             'match': labels[predictions[i][0]] in d.answer,
                             'score': math.exp(predictions[i][1])})

#Remove labels from label_strs that don't exist
#Ground_truth and predictions are nested list of idx
def relabel(ground_truth, predictions, label_strs):
    label_set = set([x for x_list in ground_truth for x in x_list] +
        [x for x_list in predictions for x in x_list])
    label_set = list(label_set)
    label_set.sort()
    new_labels = [label_strs[x] for x in label_set]
    new_labels_idx = dict(zip(label_set, range(len(label_set))))

    for i in range(len(ground_truth)):
        new_gt = [new_labels_idx[x] for x in ground_truth[i]]
        new_pred = [new_labels_idx[x] for x in predictions[i]]

        ground_truth[i] = new_gt
        predictions[i] = new_pred

    return new_labels


def visualize_results(data, predictions, label_strs, save_file_prefix):

    #Focus on labels that actually have an example
    ground_truth = [x.targets.data.tolist() for x in data]
    prediction_labels = [[x[0]] for x in predictions]
    new_labels = relabel(ground_truth, prediction_labels, label_strs)

    # Per class precision/recall report
    mb = MultiLabelBinarizer(classes=range(len(new_labels)))
    mb.fit(ground_truth + prediction_labels)
    report_str = classification_report(mb.transform(ground_truth),
                                       mb.transform(prediction_labels), target_names=new_labels)
    report = report_str.split("\n")
    report = [re.split("\s\s+", x) for x in report]

    with open(save_file_prefix + '_report.csv', 'w') as csvfile:
        writer = csv.writer(csvfile)
        writer.writerows(report)

    #Confusion Matrix
    M = confusion_matrix(ground_truth, prediction_labels)
    with open(save_file_prefix + '_confusion.csv', 'w') as csvfile:
        writer = csv.writer(csvfile)
        writer.writerow([''] + new_labels)
        for i in range(len(new_labels)):
            writer.writerow([new_labels[i]] + list(M[:,i]))


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Generate analysis files from trained model')
    parser.add_argument('network_type', help='1=token net; 2=image_token net; 3=SAN', type=int)
    parser.add_argument('data_file', help='Pickle file generated by DataLoader')
    parser.add_argument('image_folder', help='Location of images')
    parser.add_argument('checkpoint_file', help='Filepath load network checkpoint.')
    parser.add_argument('--hidden_dim', dest='hidden_dim', type=int, default=100,
                        help='Size of LSTM embedding (Default:100)')
    parser.add_argument('--use_tokens', dest='use_tokens', type=bool, default=True,
                        help='If false, ignores pos token features. (Default:True)')
    parser.add_argument('--tag_dim', dest='tag_dim', type=int, default=10,
                        help='Size of tag embedding. If <1, will use one-hot representation (Default:10)')
    parser.add_argument('save_file', help='Location to save predictions csv file')

    args = parser.parse_args()

    data = load_data(args.data_file)

    #Load Model
    use_cuda = torch.cuda.is_available()
    if(args.network_type==1):
        model = LSTMClassifier(data.embed, len(data.tags_to_idx), args.hidden_dim, len(data.labels),
                           tag_embedding_dim=args.tag_dim, use_tokens=args.use_tokens, use_cuda=use_cuda)
    elif(args.network_type==2):
        model = LSTMPlusImageClassifier(data.embed, len(data.tags_to_idx), args.hidden_dim, args.hidden_dim, len(data.labels),
                           tag_embedding_dim=args.tag_dim, use_tokens=args.use_tokens, use_cuda=use_cuda)
    elif(args.network_type==3):
        model=SAN(data.embed, args.hidden_dim, args.hidden_dim, len(data.labels), use_cuda)
    else:
        print("Model type unsupported. Supported Models: 1=token net; 2=image_token net; 3=SAN")
        exit()

    model.load_model(args.checkpoint_file)

    print(model.total_loss)

    #Image preloader
    imageset = dset.ImageFolder(root=args.image_folder, transform=model.transform)
    parameters = {'images': imageset}

    #Run test set
    test_data = [data.instances[i] for i in data.indices]
    predictions = model.make_prediction(test_data, parameters)
    save_prediction_csv(test_data, predictions, data.labels, args.save_file)
    visualize_results(test_data, predictions, data.labels, args.save_file)
